\pdfminorversion=4
\documentclass[aspectratio=169]{beamer}

\mode<presentation>
{
  \usetheme{default}
  \usecolortheme{default}
  \usefonttheme{default}
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[frame number]  % or "page number"
  \setbeamercolor{frametitle}{fg=white}
  \setbeamercolor{footline}{fg=black}
} 

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{tikz}
\usepackage{courier}
\usepackage{array}
\usepackage{bold-extra}
\usepackage{minted}
\usepackage[thicklines]{cancel}
\usepackage{fancyvrb}

\xdefinecolor{dianablue}{rgb}{0.18,0.24,0.31}
\xdefinecolor{darkblue}{rgb}{0.1,0.1,0.7}
\xdefinecolor{darkgreen}{rgb}{0,0.5,0}
\xdefinecolor{darkgrey}{rgb}{0.35,0.35,0.35}
\xdefinecolor{darkorange}{rgb}{0.8,0.5,0}
\xdefinecolor{darkred}{rgb}{0.7,0,0}
\definecolor{darkgreen}{rgb}{0,0.6,0}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\title[2021-05-04-hllhc-workshop]{Pythonic Data Analysis}
\author{Jim Pivarski}
\institute{Princeton University -- IRIS-HEP}
\date{May the 4$^{\mbox{\scriptsize th}}$ be with you}

\usetikzlibrary{shapes.callouts}

\begin{document}

\logo{\pgfputat{\pgfxy(0.11, 7.4)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\mbox{\hspace{-8 cm}\includegraphics[height=1 cm]{princeton-logo-long.png}\hspace{0.1 cm}\raisebox{0.1 cm}{\includegraphics[height=0.8 cm]{iris-hep-logo-long.png}}\hspace{0.1 cm}}}}}

\begin{frame}
  \titlepage
\end{frame}

\logo{\pgfputat{\pgfxy(0.11, 7.4)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\mbox{\hspace{-8 cm}\includegraphics[height=1 cm]{princeton-logo.png}\hspace{0.1 cm}\raisebox{0.1 cm}{\includegraphics[height=0.8 cm]{iris-hep-logo.png}}\hspace{0.1 cm}}}}}

% Uncomment these lines for an automatically generated outline.
%\begin{frame}{Outline}
%  \tableofcontents
%\end{frame}

% START START START START START START START START START START START START START

\begin{frame}{}
\LARGE
\begin{center}
\textcolor{darkblue}{Part 1: Trends in data analysis software}

\vspace{0.5 cm}
\textcolor{lightgray}{Part 2: Status of Pythonic HEP software}
\end{center}
\end{frame}

\begin{frame}{Pythonic data analysis in the HL-LHC era?}
\vspace{0.25 cm}
\begin{center}
\only<1>{\includegraphics[width=0.9\linewidth]{hllhc-python-timeline-0.pdf}}\only<2>{\includegraphics[width=0.9\linewidth]{hllhc-python-timeline-1.pdf}}\only<3>{\includegraphics[width=0.9\linewidth]{hllhc-python-timeline-2.pdf}}\only<4>{\includegraphics[width=0.9\linewidth]{hllhc-python-timeline-3.pdf}}\only<5>{\includegraphics[width=0.9\linewidth]{hllhc-python-timeline-4.pdf}}\only<6>{\includegraphics[width=0.9\linewidth]{hllhc-python-timeline-5.pdf}}
\end{center}
\end{frame}

\begin{frame}{What were the physicists doing in this decade?}
\vspace{0.35 cm}

Primary language of GitHub repos created by users who forked CMSSW:

\vspace{-0.6 cm}
\includegraphics[width=\linewidth]{lhlhc-github-languages.pdf}
\end{frame}

\begin{frame}{Consistent with survey results (PyHEP 2020 participants)}
\vspace{0.2 cm}
\begin{columns}
\column{1.15\linewidth}
\only<1>{\includegraphics[width=\linewidth]{pyhep2020-survey-1.pdf}}\only<2>{\includegraphics[width=\linewidth]{pyhep2020-survey-2.pdf}}\only<3>{\includegraphics[width=\linewidth]{pyhep2020-survey-3.pdf}}\only<4>{\includegraphics[width=\linewidth]{pyhep2020-survey-4.pdf}}\only<5>{\includegraphics[width=\linewidth]{pyhep2020-survey-5.pdf}}
\end{columns}
\end{frame}

\begin{frame}{Pythonic analysis is mainstream, and the trend preceded Uproot}
\vspace{0.35 cm}

GitHub repos matching search strings: Pythonic analysis is as common as ``TFile''.

\vspace{-0.6 cm}
\includegraphics[width=\linewidth]{lhlhc-github-overlay-lin.pdf}
\end{frame}

\begin{frame}{This is also consistent with self-reported usage}
\vspace{-0.35 cm}
\begin{columns}
\column{1.1\linewidth}
\includegraphics[width=\linewidth]{lhlhc-familiarity-with-packages.pdf}
\end{columns}
\end{frame}

\begin{frame}{}
\LARGE
\begin{center}
\textcolor{lightgray}{Part 1: Trends in data analysis software}

\vspace{0.5 cm}
\textcolor{darkblue}{Part 2: Status of Pythonic HEP software}
\end{center}
\end{frame}

\begin{frame}{Not a single group, but mostly shared vision}
\vspace{0.4 cm}
\begin{center}
\begin{minipage}{0.83\linewidth}
\large
Most of the developers of Pythonic HEP software

\vspace{0.25 cm}
\begin{itemize}\setlength{\itemsep}{0.2 cm}
\item \textcolor{darkblue}{aim for small package granularity}, providing tools that address a well-defined class of problems at one level of abstraction,
\item \textcolor{darkblue}{aim for interoperability} with each other and the larger Pythonic ecosystem,
\item \textcolor{darkblue}{avoid overlapping functionality}, by communicating through HSF and IRIS-HEP channels,
\item \textcolor{darkblue}{focus on domain-specific problems} that won't be addressed by non-HEP software \underline{\it or} \textcolor{darkblue}{focus on connecting HEP-specific tools} to the larger ecosystem.
\end{itemize}
\end{minipage}
\end{center}
\end{frame}

%% \begin{frame}{Unshared vision}
%% \vspace{0.4 cm}
%% \begin{center}
%% \begin{minipage}{0.83\linewidth}
%% \large
%% Some people in this area are trying to replace ROOT.

%% \vspace{0.4 cm}
%% Others (myself included) are connect everything to everything, so that there are no artificial boundaries in data analysis.

%% \vspace{0.4 cm}
%% End-user analysis is a decentralized world. Small, interoperating tools have historically worked well in that environment.
%% \end{minipage}
%% \end{center}
%% \end{frame}

\begin{frame}{Scikit-HEP: a clearinghouse for Pythonic HEP software}
\vspace{0.35 cm}
\begin{columns}
\column{0.8\linewidth}
\includegraphics[width=\linewidth]{early-scikit-hep.png}
\column{0.28\linewidth}

Originally conceived as a core package with ``affiliates'' like AstroPy; now it's ``just affiliates.''

\vspace{0.2 cm}
A common brand for packages that work together and with the Python ecosystem.
\end{columns}
\end{frame}

\begin{frame}{Scikit-HEP's 5 pillars today:}
\vspace{0.2 cm}

\begin{description}\setlength{\itemsep}{0.1 cm}
\item[Simulation:] other than \mintinline{python}{numpythia} and \mintinline{python}{pyhepmc}, this is mostly left to non-Python packages (which fill files that can be read with Python).

\item[Datasets:] \mintinline{python}{root-numpy}, \mintinline{python}{uproot}, \mintinline{python}{pylhe}, \mintinline{python}{awkward}, as well as \mintinline{python}{numpy} and \mintinline{python}{pandas}. Some use HDF5/\mintinline{python}{h5py} because of its recognition by ML tools.

\item[Aggregations:] \mintinline{python}{boost-histogram}/\mintinline{python}{hist}, \mintinline{python}{coffea}, \mintinline{python}{fast-carpenter}.

\item[Modeling/fitting:] by far, the most covered: \mintinline{python}{pyhf} (dozens of publications), \mintinline{python}{iminuit}, \mintinline{python}{zfit}, \mintinline{python}{hepstats}, \mintinline{python}{goofit}, \mintinline{python}{SModelS}, direct use of Pandas, ML\ldots

\item[Visualization:] most modeling tools output to \mintinline{python}{matplotlib}, \mintinline{python}{mplhep} is widely used as a dependency. \mintinline{python}{coffea}, \mintinline{python}{hist}, \mintinline{python}{histoprint}.

\end{description}

\vspace{0.15 cm}
Should also add \textcolor{darkblue}{Distributed computing:} some \mintinline{python}{pyspark}, but more \mintinline{python}{dask}, often through \mintinline{python}{coffea} (future \mintinline{python}{coffea-casa}/ServiceX).

\vspace{0.15 cm}
Should also add \textcolor{darkblue}{Acceleration/JIT-compilation:} \mintinline{python}{numba}, \mintinline{python}{jax}, \mintinline{python}{ROOT.RDataFrame}.

\vspace{0.15 cm}
Should also add \textcolor{darkblue}{HEP domain-specific:} corrections in \mintinline{python}{coffea}, Lorentz vectors in \mintinline{python}{vector}, PDG in \mintinline{python}{particle}, jet clustering in \mintinline{python}{pyjet}\ldots
\end{frame}

\begin{frame}{Status/readiness for the HL-LHC:}
\vspace{0.2 cm}

\setbeamercolor{description body}{fg=gray}
\setbeamercolor{alerted text}{fg=black}

\begin{description}[<+-|alert@+>]
\item[\textcolor{darkblue}{Simulations:}] don't need to be in Python (much like event reconstruction).

\item[\textcolor{darkblue}{Datasets:}] mostly covered, especially as minimalist formats like NanoAOD catch on. Pythonic access to RNTuple will be needed and is in development.

\item[\textcolor{darkblue}{Aggregations:}] need better interop between boost-histograms and ROOT histograms. Also, common usage is tending toward ``superhistograms,'' collections that describe systematic variations that ought to have shared metadata.

\item[\textcolor{darkblue}{Modeling/fitting:}] \underline{well-covered:} needs are highly specialized and practitioners write their own packages. \mintinline{python}{scikit-hep/cookie} simplifies package-creation.

\item[\textcolor{darkblue}{Visualization:}] in rapid development now, and mostly centralized in a few packages.

\item[\textcolor{darkblue}{Distributed computing:}] early experiments with a wide variety of options are mostly narrowing on Dask, though I think we should keep an eye on Ray. The Query System concept is in rapid development in IRIS-HEP/ServiceX.

\item[\textcolor{darkblue}{Acceleration:}] Awkward Arrays and Lorentz vectors can be JIT-compiled with Numba; histogramming is next. Awkward Arrays should also become interoperable with RDataFrame so we have both Python and C++ JIT-compilation.

\item[\textcolor{darkblue}{HEP domain-specific:}] \mintinline{python}{coffea} covers each use-case before it gets its own library.
\end{description}
\end{frame}

\begin{frame}{Breakdown by strategy}
\vspace{0.3 cm}
\begin{columns}[t]
\column{0.33\linewidth}
\underline{\large Domain-specific stuff we do}

\vspace{0.15 cm}
\begin{itemize}
\item (super)histograms as fillable objects
\item HEP-style plots (pulls, Brazil, efficiency\ldots)
\item ansatz fitting, limit setting, discovery significance
\item applying corrections, clustering, Lorentz vector manipulation
\end{itemize}

\column{0.33\linewidth}
\underline{\large Connections to externals}

\vspace{0.15 cm}
\begin{itemize}
\item ROOT, LHE files $\leftrightarrow$ arrays, Pandas, ML
\item using ML packages to do HEP fits: \mintinline{python}{pyhf}/\mintinline{python}{combinetf}
\item extending Numba for jagged arrays, Lorentz vectors, histogramming
\item events $\to$ histograms workflow in distributed computing frameworks
\item building Query Systems out of standard parts
\end{itemize}

\column{0.33\linewidth}
\underline{\large External libraries we use}

\vspace{0.15 cm}
\begin{itemize}
\item machine learning
\item distributed computing
\item JIT-compilation
\item autodifferentiation
\item interactive notebooks
\end{itemize}

\end{columns}
\end{frame}

\begin{frame}{Conclusions}
\vspace{0.5 cm}
\large

The question is not quite, ``Will the whole ecosystem be ready for the HL-LHC?''

\vspace{0.25 cm}
Many pieces are in-use \underline{\it now}, and they're growing to fill real analysis needs \underline{\it now}.

\vspace{0.25 cm}
\begin{itemize}\setlength{\itemsep}{0.25 cm}
\item I personally know of $\sim$10 analyses using Python almost exclusively

(CMS $H \to \gamma\gamma$, $\to \mu\mu$, $\to c\bar{c}$, di-Higgs, top EFT, Dazsle analyses\ldots).

\item There is a wave of such analyses gradually approaching publication.
\end{itemize}

\vspace{0.6 cm}
From current trends, it looks like Pythonic

analysis will either predominate in Run 3

or stay evenly mixed with C++, it is today.

\vspace{-2.5 cm}
\hfill \mbox{\includegraphics[width=0.55\linewidth]{lhlhc-github-overlay-lin.pdf}\hspace{-1 cm}}

\vspace{-0.5 cm}
%% \vspace{0.5 cm}
%% The ``interoperating, small packages'' model has considerable flexibility, for
%% \begin{itemize}
%% \item addressing new needs (e.g.\ \mintinline{python}{histoprint}),
%% \item letting unnecessary projects go (e.g.\ MC in Python), and
%% \item taking over maintenance (e.g.\ current revamp of \mintinline{python}{pyjet}).
%% \end{itemize}
\end{frame}

\end{document}
